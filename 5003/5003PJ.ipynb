{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147.256175995\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "start = time.time()\n",
    "Slength = 0\n",
    "hashList=[]\n",
    "bandNum = 50\n",
    "FunNumber = 300\n",
    "trainPath = \"./2000train/*.txt\"\n",
    "testPath = \"./testDoc/*.txt\"\n",
    "def generateHashFun():\n",
    "    '''300 hash functions'''\n",
    "    x = [2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101,103,107,109,\n",
    "         113,127,131,137,139,149,151,157,163,167,173,179,181,191,193,197,199,211,223,227,229,233,\n",
    "         239,241,251,257,263,269,271,277,281,283,293,307,311,313,317,331,337,347,349,353,359,367,\n",
    "         373,379,383,389,397,401,409,419,421,431,433,439,443,449,457,461,463,467,479,487,491,499,\n",
    "         503,509,521,523,541,547,557,563,569,571,577,587,593,599,601,607,613,617,619,631,641,643,\n",
    "         647,653,659,661,673,677,683,691,701,709,719,727,733,739,743,751,757,761,769,773,787,797,\n",
    "         809,811,821,823,827,829,839,853,857,859,863,877,881,883,887,907,911,919,929,937,941,947,\n",
    "         953,967,971,977,983,991,997,1009,1013,1019,1021,1031,1033,1039,1049,1051,1061,1063,1069,\n",
    "         1087,1091,1093,1097,1103,1109,1117,1123,1129,1151,1153,1163,1171,1181,1187,1193,1201,1213,\n",
    "         1217,1223,1229,1231,1237,1249,1259,1277,1279,1283,1289,1291,1297,1301,1303,1307,1319,1321,\n",
    "         1327,1361,1367,1373,1381,1399,1409,1423,1427,1429,1433,1439,1447,1451,1453,1459,1471,1481,\n",
    "         1483,1487,1489,1493,1499,1511,1523,1531,1543,1549,1553,1559,1567,1571,1579,1583,1597,1601,\n",
    "         1607,1609,1613,1619,1621,1627,1637,1657,1663,1667,1669,1693,1697,1699,1709,1721,1723,1733,\n",
    "         1741,1747,1753,1759,1777,1783,1787,1789,1801,1811,1823,1831,1847,1861,1867,1871,1873,1877,\n",
    "         1879,1889,1901,1907,1913,1931,1933,1949,1951,1973,1979,1987]\n",
    "    for i in x:\n",
    "        hashList.append(_hf(i))\n",
    "def _hf(multy):\n",
    "    return lambda x: ((multy % Slength) * (x%Slength) +1) % Slength\n",
    "\n",
    "def caculateKeyID(string):\n",
    "    '''\n",
    "    Caculate key words' ID by its value\n",
    "    '''\n",
    "    sumID = 0\n",
    "    for i in range(0,len(string),2):\n",
    "        sumID = (ord(string[i]) - 64) + i*26\n",
    "    return sumID\n",
    "def getKeyWords(wordList):\n",
    "    '''\n",
    "    If word List is ['A','B','C','D','E','F','G'],\n",
    "    Return Value is ['ABC','BCD','CDE','DEF','EFG']\n",
    "    '''\n",
    "    arr = []\n",
    "    for i in range(len(wordList)-3):\n",
    "        arr.append(\"\".join(wordList[i:i+3]))\n",
    "    return arr\n",
    "\n",
    "def getHashValues(item):\n",
    "    '''\n",
    "    item is like ((\"wordA wordB wordC\",[columnX1,columnX2,columnX2]),rowID)\n",
    "    With a List of Hash Functions, caculate hash values by rowID\n",
    "    return a list of hash values\n",
    "    '''\n",
    "    arr = []\n",
    "    for i in range(FunNumber):\n",
    "        arr.append(((i,hashList[i](item[1])),item[0][1]))\n",
    "    return arr\n",
    "\n",
    "def parallelRead(path):\n",
    "    '''\n",
    "    Read directory in parallel, Return a RDD List of item \n",
    "    who is like ((\"wordA wordB wordC\",[columnX1,columnX2,columnX2]),rowID)\n",
    "    Where \"wordA wordB wordC\" appear continuously and columnX is the document ID it appears\n",
    "    '''\n",
    "    rdd = sc.wholeTextFiles(path,4).map(lambda x: (x[0],x[1].split(\" \"))).map(lambda x: (x[0],getKeyWords(x[1]))).zipWithUniqueId()\n",
    "    fileDict = rdd.map(lambda x:(x[0][0],x[1]))\n",
    "    dataRDD = rdd.map(lambda x:(x[1],x[0][1])).flatMapValues(lambda x: x).map(lambda x: (x[1],x[0])).groupByKey().mapValues(list).map(lambda x:((x[0],x[1]),caculateKeyID(x[0])))\n",
    "    return dataRDD,fileDict\n",
    "def getSignature(X):\n",
    "    '''\n",
    "    Return a RDD--Signature Matrix with shape ((rowID, columnID),hashValue)\n",
    "    '''\n",
    "    X1 = X.map(lambda x:getHashValues(x)).flatMap(lambda x: x).flatMapValues(lambda x: x)\n",
    "    return X1.map(lambda x: ((x[0][0],x[1]),x[0][1])).groupByKey().mapValues(lambda x: min(list(x)))\n",
    "\n",
    "def equalBucket(List):\n",
    "    '''\n",
    "    List is ((bandID, columnID),[((bandID, columnID),value),((bandID, columnID),value),((bandID, columnID),value)])\n",
    "    use a hash function to get bucket ID\n",
    "    '''\n",
    "    tp = ''\n",
    "    for i in range(0,len(List),2):\n",
    "        tp+=str(List[i][1])\n",
    "    return tp\n",
    "X,fileDict = parallelRead(trainPath)\n",
    "Slength = X.count()\n",
    "generateHashFun()\n",
    "Signature = getSignature(X)\n",
    "'''\n",
    "bucket's item like ((bandRowID,backetValue),[columnID_1,columnID_2...])\n",
    "'''\n",
    "BucketTable = Signature.groupBy(lambda x: (x[0][1],x[0][0] % bandNum)).mapValues(list).map(lambda x: ((x[0][1],equalBucket(x[1])),x[0][0])).groupByKey().mapValues(list)\n",
    "testDocs,testName = parallelRead(testPath)\n",
    "testSignature = getSignature(testDocs)\n",
    "testBucket = testSignature.groupBy(lambda x: (x[0][1],x[0][0] % bandNum)).mapValues(list).map(lambda x: ((x[0][1],equalBucket(x[1])),x[0][0])).groupByKey().mapValues(list)\n",
    "def getPossibleDoc():\n",
    "    '''\n",
    "    columnID is ID in signature Matrix, which is actually documentID\n",
    "    return RDD's item is like (columnID_AIM,[columnID_X1,columnID_X2,columnID_X3,...,columnID_Xn]) \n",
    "    columnID_AIM is the document we want to find its similar docs\n",
    "    columnID_X is possible similar docs in same bucket\n",
    "    '''\n",
    "    def Filter(x):\n",
    "        if x[0]==None:\n",
    "            return ''\n",
    "        return (x[1],x[0])\n",
    "    T = testBucket.leftOuterJoin(BucketTable).map(lambda x: (x[1][1],x[1][0])).flatMapValues(lambda x: x).filter(lambda x:x[0]!=None).map(lambda x:(x[1],x[0]))\n",
    "    return T.groupByKey().mapValues(list).map(lambda x: (x[0],list(set(reduce(lambda a,b:a+b, x[1])))))\n",
    "Arrs = getPossibleDoc().collect()\n",
    "test_ID = 0\n",
    "Source_ID = Arrs[0][1]\n",
    "tempFileName = fileDict.filter(lambda x:x[1] in Source_ID).map(lambda x: ((x[1],0),x[0]))\n",
    "T2 = testSignature.filter(lambda x: x[0][1] == test_ID).map(lambda x: ((x[0][0],x[1]),x[0][1]))\n",
    "T1 = Signature.filter(lambda x: x[0][1] in Source_ID).map(lambda x: ((x[0][0],x[1]),x[0][1]))\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.3618099689\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "jacSim = T1.join(T2).map(lambda x: (x[1],x[0])).groupByKey().mapValues(len).map(lambda x: (x[0],x[1]/float(2 * FunNumber - x[1])))\n",
    "FindFileName = [(x, tuple(map(list, y))) for x, y in sorted(list(jacSim.cogroup(tempFileName).collect()))]\n",
    "print (time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.2761211395\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "newjacSim = Signature.map(lambda x: ((x[0][0],x[1]),x[0][1])).join(testSignature.map(lambda x: ((x[0][0],x[1]),x[0][1]))).map(lambda x: (x[1],x[0])).groupByKey().mapValues(len).map(lambda x: (x[0],x[1]/float(2 * FunNumber - x[1])))\n",
    "newFindFileName = [(x, tuple(map(list, y))) for x, y in sorted(list(newjacSim.cogroup(tempFileName).collect()))]\n",
    "print (time.time() - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
